---
title: "Decision trees for machine learning"
#output: html_notebook
output: html_document
#editor_options: 
  #chunk_output_type: inline
---

Topics

* rpart
* Caret
* SuperLearner
* h2o.ai
* mlr
* book

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. Use the latest RStudio preview release to run within RStudio.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
# Load iris dataset.
data(iris)

# Review data structure.
str(iris)

# Review species distribution.
table(iris$Species, useNA = "ifany")

# Review all variables.
summary(iris)
```

```{r}
# install rpart first if you don't already have it.
# install.packages("rpart")
# rpart = recursive partitioning and regression trees (aka decision trees)
library(rpart)

# Review package help and vignette if available.
# HINT: vignette covers all of this in much better detail.
help(package = "rpart")

# To be reproducible we need to set a seed due to randomness in the cross-validation.
set.seed(1)

# Fit a classification decision tree to predict Species using all other variables.
# We don't need to specify method="class" because Species is a factor variable.
# For regression we'd do method = "anova" (default if outcome variable is not a factor)
tree_model = rpart(Species ~ ., data = iris)

# Display the decision tree in text form.
tree_model

# Plot tree graphically.
plot(tree_model, compress = T)
# We have to add the plot text manually for some reason.
# NOTE: you may need to select the plot() and text() lines and run them simultaneously
# depending on your RStudio settings, e.g. if you get a "plot.new has not been called yet" error.
text(tree_model, use.n = T)
```

Wow, this is one of the worst plots I've ever seen! Hard to get much worse than that.

The help pages will give more details on the function arguments as well as handy examples.

```{r}
# Review main decision tree function.
?rpart

# Review the configuration options for trees.
?rpart.control

# Same thing as above but with explicitly setting key options.
# We specify 10 cross-validation folds to determine the best complexity.
# Minbucket is the minimum number of observations in a node.
# Tip: I put parentheses around the whole line so that the result is printed.
(tree_model = rpart(Species ~ ., data = iris,
                    control = rpart.control(xval = 10, minbucket = 5, cp = 0.01)))

```


Let's get a better decision tree plotting package.

```{r}
# Install from CRAN if you don't already have this:
# install.packages("rpart.plot")
library(rpart.plot)

rpart.plot(tree_model)

# What other settings can we modify?
?rpart.plot

# Review the vignette if interested.
help(package = "rpart.plot")

# Another way to plot it.
library(partykit)
plot(as.party(tree_model))

# fancyRpartPlot() in the rattle package is also good.

```

We can dig into the details of the tree a bit more.

```{r}
# Review accuracy for different complexity parameters.
# When nsplits = 0 we have 0 nodes and are merely guessing the most common class.
# When nsplits is large we have 1  + # splits nodes and each node is its own prediction.
printcp(tree_model)

# Save the complexity parameter table, and also print.
cp_table = printcp(tree_model)

# Review structure of the cp table.
str(cp_table)

# Which row has minimum cross-validation error?
# Alternatively we could choose the tree within 1 SD of the minimum.
best_row = cp_table[which.min(cp_table[, "xerror"]), ]
best_row
best_row["CP"]

# Get all the details on the tree.
summary(tree_model, cp = best_row["CP"])

# Prune to the optimal complexity parameter (no change in this case).
tree_model = prune(tree_model, cp = best_row["CP"])

tree_model
```

We did not create a separate holdout or test set, so let's predict back on the original data.

```{r}
predictions = predict(tree_model, iris)
summary(predictions)

# How do the predictions look compared to the outcome data?
data.frame(iris$Species, predictions)

# This is an optimistic view because the model was built on this same data.
# With a random holdout set we would get a more realistic view of accuracy.

```

## Regression

Quick regression example.
```{r}
# This data is in the rpart package.
data(car90)

# Review structure of dataset.
str(car90)

# Set seed due to cross-validation randomness.
set.seed(1)

# Predict price using most other fields.
# Remove a few fields that are too predictive (rim) or too many categories.
reg_tree = rpart(Price ~ ., data = car90[, !names(car90) %in% c("Rim", "Tires", "Model2")])

# How'd it go?
reg_tree

# Review complexity parameter options.
printcp(reg_tree)

# Visualize results across complexity parameter.
rsq.rpart(reg_tree)

# Save the complexit parameter table.
cp_table = printcp(reg_tree)

# Which row has minimum cross-validation error?
(best_row = cp_table[which.min(cp_table[, "xerror"]), ])
best_row["CP"]

# Review summary with the best complexity parameter.
summary(reg_tree, cp = best_row["CP"])

# Prune our tree back to the best complexity parameter.
# Note that in this case no real pruning is needed, because
# the full tree is the best.
reg_tree = prune(reg_tree, cp = best_row["CP"])

# Visualize our final tree.
rpart.plot(reg_tree)

```

# Caret

```{r}
library(caret)

# Nice and simple - using default settings for everything.
# caret tries 3 complexity parameters by default, but tuneLength customizes that.
model = train(Species ~ ., data = iris, method = "rpart", tuneLength = 5)

# We see again that cp= 0 gives us the best accuracy.
model

# Use the handy built-in caret plotting.
plot(model)

# Look at the final model object (rpart).
model$finalModel
```

# SuperLearner

SuperLearner unfortunately cannot do multiple-class classification (yet) so let's convert to a binary classification problem.

```{r}

# Review 
table(iris$Species)

# Copy into a new dataframe.
data = iris

# Convert Species to a binary indicator for setosa.
data$Species = as.integer(data$Species == "versicolor")

# Confirm distribution of modified outcome variable.
table(data$Species, iris$Species, useNA = "ifany")

library(SuperLearner)

set.seed(1)

# family = binomial() is used for classification; family = gaussian() for regression.
sl = SuperLearner(X = data[, -5], Y = data$Species, family = binomial(),
                  SL.library = c("SL.mean", "SL.rpart"))
sl

# Review the raw rpart object.
sl$fitLibrary$SL.rpart_All$object

# Use our nice plotting library.
rpart.plot::rpart.plot(sl$fitLibrary$SL.rpart_All$object)

```

# h2o.ai

We can get close to a single decision tree by using randomForest in h2o. We set RF to fit a single decision tree and to search all variables at each split. It will not be exactly the same due to boostrap sampling but will be similar.

```{r}
# install.packages("h2o") # version 3.16
# Or version 3.18:
# install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/1/R")
# Or nightly release (3.19):
# install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/master/4203/R")
library(h2o)

# Start h2o backend.
h2o.init(nthreads = -1)

# Load iris data into h2o.
iris_h2o = h2o.uploadFile(path = system.file("extdata", "iris_wheader.csv",
                                             package = "h2o"),
                          destination_frame = "iris_h2o")

# Confirm it loaded correctly.
summary(iris_h2o)

# Specify x and y by the column indices.
# Set ntree to 1, and mtries to # of covariates.
# Seed only reproducible when running single-threaded.
iris_tree = h2o.randomForest(y = 5, x = 1:4, training_frame = iris_h2o,
                             ntrees = 1, mtries = 4, seed = 1)

# Review results.
iris_tree

summary(iris_tree)

# Review variable importance.
h2o.varimp(iris_tree)

# Plot variable importance - nice.
h2o.varimp_plot(iris_tree)

# Shutdown h2o backend.
h2o.shutdown(prompt = F)
```

h2o debugging notes:

* If you get a "connection refused" error it may mean that your version of Java is too new.
  * Java must be JDK 8; h2o does not yet support JDK 9.
  * More info here: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/faq/java.html
  * Info on how to install JDK8 with homebrew here: http://www.lonecpluspluscoder.com/2017/10/08/installing-other-versions-of-the-java-jdk-via-homebrew/

# mlr

```{r}
library(mlr)

# Generate the task for multiple classification (also works for binary).
task = makeClassifTask(data = iris, target = "Species")

# Get the number of observations
n = getTaskSize(task)

# Generate the learners.
learners = list(makeLearner("classif.rpart", id = "rpart", predict.type = "prob"))

# 5-fold cross-validation, stratifying on Y to ensure balance across folds.
# could use stratify.cols to stratify on certain important covariates.
rdesc = makeResampleDesc("CV", iters = 5L, stratify = TRUE)

# Fit model across cross-validation folds and calculate the performance.
result = benchmark(learners, task, rdesc, measures = list(acc, mmce))

# MMCE = mean misclassification error (i.e. 1 - accuracy)
result

# Plot the results. Generally we would plot multiple models here.
plotBMRBoxplots(result, measure = acc)
```


# Decision tree references

Awesome new data camp course: [Machine Learning with Tree-based Models in R](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-r)

  * By Berkeley's own Erin LeDell, now machine learning scientist at h2o.ai

This book has nearly everything you would want to know about the theory of decision trees:

Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). Classification and regression trees. CRC press.

The book has 32,000 citations according to Google Scholar. Not too shabby! Breiman and Stone were both Berkeley professors, and Breiman invented Random Forest, bagging, and some of the theory for SuperLearner & gradient boosted machines. Friedman is at Stanford and invented many other machine learning algorithms, particularly gradient boosted machines GBM) and multivariate adaptive regression splines (MARS). Olshen is also at Stanford.
