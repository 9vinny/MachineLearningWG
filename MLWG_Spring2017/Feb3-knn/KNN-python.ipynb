{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the relevant libraries, namely the dataset, Python's `numpy`, a graphing library, and the machine learning library `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston dataset was originally devised for regression, so we'll first show a simple regression model in `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic single model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and split into training and testing portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41270653,  0.92862338, -1.30687771, ..., -0.02567665,\n",
       "         0.44105193, -0.71811916],\n",
       "       [-0.41548823,  1.87285388, -1.07342276, ..., -0.39556665,\n",
       "         0.44105193, -0.76717998],\n",
       "       [-0.39175357, -0.48772236, -0.61672651, ..., -0.2568579 ,\n",
       "         0.3954402 ,  0.86163938],\n",
       "       ..., \n",
       "       [ 0.26527877, -0.48772236,  1.01599907, ...,  0.80657583,\n",
       "         0.44105193,  0.94153844],\n",
       "       [-0.3799724 , -0.48772236, -0.72032214, ..., -0.48803915,\n",
       "         0.22012011, -0.24853698],\n",
       "       [-0.40911792, -0.48772236, -0.75534039, ...,  0.34421334,\n",
       "         0.44105193, -0.54430367]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X, y = shuffle(boston.data, boston.target, random_state=1)\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep with how we determined `k` in `R`, by taking the square root of the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 20\n"
     ]
    }
   ],
   "source": [
    "k = int(len(X_train) ** (1/2))\n",
    "print(\"k: \" + str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the parameters for the model, and given them to the model object, fit the model to the data, and calculate the MSE on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 34.5423\n",
      "0.619724559909\n"
     ]
    }
   ],
   "source": [
    "params = {'n_neighbors': k, 'weights': \"uniform\"}\n",
    "\n",
    "kkn_r = neighbors.KNeighborsRegressor(**params)\n",
    "\n",
    "kkn_r.fit(X_train, y_train)\n",
    "mse = mean_squared_error(y_test, kkn_r.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(kkn_r.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more thorough analysis allows for checking multiple values for any parameter, let's look for the best model by looking at a range of values for `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'weights': ['uniform'], 'n_neighbors': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(int(k-(k/2)), int(k+(k/2)), 1),\n",
    "              'weights': [\"uniform\"]}\n",
    "\n",
    "knn_r = GridSearchCV(neighbors.KNeighborsRegressor(), param_grid)\n",
    "knn_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validated results come in the form of a dictionary with the following keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'mean_train_score',\n",
       " 'param_n_neighbors',\n",
       " 'param_weights',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_test_score',\n",
       " 'split1_train_score',\n",
       " 'split2_test_score',\n",
       " 'split2_train_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(knn_r.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know explicitly which parameter combinations were computed, we can check the `params` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 10, 'weights': 'uniform'},\n",
       " {'n_neighbors': 11, 'weights': 'uniform'},\n",
       " {'n_neighbors': 12, 'weights': 'uniform'},\n",
       " {'n_neighbors': 13, 'weights': 'uniform'},\n",
       " {'n_neighbors': 14, 'weights': 'uniform'},\n",
       " {'n_neighbors': 15, 'weights': 'uniform'},\n",
       " {'n_neighbors': 16, 'weights': 'uniform'},\n",
       " {'n_neighbors': 17, 'weights': 'uniform'},\n",
       " {'n_neighbors': 18, 'weights': 'uniform'},\n",
       " {'n_neighbors': 19, 'weights': 'uniform'},\n",
       " {'n_neighbors': 20, 'weights': 'uniform'},\n",
       " {'n_neighbors': 21, 'weights': 'uniform'},\n",
       " {'n_neighbors': 22, 'weights': 'uniform'},\n",
       " {'n_neighbors': 23, 'weights': 'uniform'},\n",
       " {'n_neighbors': 24, 'weights': 'uniform'},\n",
       " {'n_neighbors': 25, 'weights': 'uniform'},\n",
       " {'n_neighbors': 26, 'weights': 'uniform'},\n",
       " {'n_neighbors': 27, 'weights': 'uniform'},\n",
       " {'n_neighbors': 28, 'weights': 'uniform'},\n",
       " {'n_neighbors': 29, 'weights': 'uniform'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_r.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_test_score` key gives the score for each of the above combinations on the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39907869,  0.39370905,  0.3894494 ,  0.38306966,  0.3740351 ,\n",
       "        0.35892923,  0.34931848,  0.33089222,  0.3246813 ,  0.32128488,\n",
       "        0.31796372,  0.30691265,  0.30151601,  0.29615633,  0.2925673 ,\n",
       "        0.28837524,  0.28258091,  0.27758829,  0.26868124,  0.26432613])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_r.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify the best scoring model with `numpy`'s `argmax` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'uniform', 'n_neighbors': 10}\n",
      "\n",
      "0.399078686639\n"
     ]
    }
   ],
   "source": [
    "best_index = np.argmax(knn_r.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(knn_r.cv_results_[\"params\"][best_index])\n",
    "print()\n",
    "print(max(knn_r.cv_results_[\"mean_test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46765454698877595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_r.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the `R` demonstration, we can also do classfication, first we'll need to convert the distances to three different groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 179, 87)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_boston = {\"data\": [],\n",
    "              \"target\": []}\n",
    "\n",
    "for i, arr in enumerate(boston[\"data\"]):\n",
    "    \n",
    "    new_arr = arr\n",
    "    \n",
    "    if arr[7] < 3:\n",
    "        new_boston[\"target\"].append(\"short\")\n",
    "    elif arr[7] < 6:\n",
    "        new_boston[\"target\"].append(\"medium\")\n",
    "    else:\n",
    "        new_boston[\"target\"].append(\"long\")\n",
    "        \n",
    "    new_arr = np.delete(new_arr, 7)\n",
    "    new_arr = np.append(new_arr, boston[\"target\"][i])\n",
    "\n",
    "    new_boston[\"data\"].append(new_arr)\n",
    "    \n",
    "new_boston[\"target\"].count(\"short\"), new_boston[\"target\"].count(\"medium\"), new_boston[\"target\"].count(\"long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can reassign the new data to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(new_boston[\"data\"], new_boston[\"target\"], random_state=1)\n",
    "X = preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29]), 'weights': ['uniform']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': np.arange(int(k-(k/2)), int(k+(k/2)), 1),\n",
    "              'weights': [\"uniform\"]}\n",
    "\n",
    "knn_c = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid)\n",
    "knn_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'mean_train_score',\n",
       " 'param_n_neighbors',\n",
       " 'param_weights',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_test_score',\n",
       " 'split1_train_score',\n",
       " 'split2_test_score',\n",
       " 'split2_train_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(knn_c.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 10, 'weights': 'uniform'},\n",
       " {'n_neighbors': 11, 'weights': 'uniform'},\n",
       " {'n_neighbors': 12, 'weights': 'uniform'},\n",
       " {'n_neighbors': 13, 'weights': 'uniform'},\n",
       " {'n_neighbors': 14, 'weights': 'uniform'},\n",
       " {'n_neighbors': 15, 'weights': 'uniform'},\n",
       " {'n_neighbors': 16, 'weights': 'uniform'},\n",
       " {'n_neighbors': 17, 'weights': 'uniform'},\n",
       " {'n_neighbors': 18, 'weights': 'uniform'},\n",
       " {'n_neighbors': 19, 'weights': 'uniform'},\n",
       " {'n_neighbors': 20, 'weights': 'uniform'},\n",
       " {'n_neighbors': 21, 'weights': 'uniform'},\n",
       " {'n_neighbors': 22, 'weights': 'uniform'},\n",
       " {'n_neighbors': 23, 'weights': 'uniform'},\n",
       " {'n_neighbors': 24, 'weights': 'uniform'},\n",
       " {'n_neighbors': 25, 'weights': 'uniform'},\n",
       " {'n_neighbors': 26, 'weights': 'uniform'},\n",
       " {'n_neighbors': 27, 'weights': 'uniform'},\n",
       " {'n_neighbors': 28, 'weights': 'uniform'},\n",
       " {'n_neighbors': 29, 'weights': 'uniform'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_c.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78712871,  0.76980198,  0.76732673,  0.77227723,  0.77970297,\n",
       "        0.76980198,  0.77970297,  0.76237624,  0.76732673,  0.76980198,\n",
       "        0.76980198,  0.76237624,  0.75247525,  0.76237624,  0.75742574,\n",
       "        0.75247525,  0.75247525,  0.75247525,  0.7450495 ,  0.75247525])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_c.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 10, 'weights': 'uniform'}\n",
      "\n",
      "0.787128712871\n"
     ]
    }
   ],
   "source": [
    "best_index = np.argmax(knn_c.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(knn_c.cv_results_[\"params\"][best_index])\n",
    "print()\n",
    "print(max(knn_c.cv_results_[\"mean_test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81372549019607843"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_c.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
