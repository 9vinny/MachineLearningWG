{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks are mainly used for image classification. Because of that, they necessarily require large amounts of data, even for just a few observations. Plus, there are several more layers of computation than the neural networks we looked at last week. Only the smallest problems (like the one here) can be done on a CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what's different about CNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick note:** In math, an nD array is called a tensor. A vector is a specific name for a 1D tensor and a matrix is a specific name for a 2D tensors. Images are usually composed of three channels, often red, green and blue. So each image is a matrix of red values, a matrix of green values, and a matrix of blue values. Thus, images are 3D tensors. That's where TensorFlow gets its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs add a step called convolution, which gives the algorithm its name. In convolution, you take a small tensor (e.g. $5\\times5\\times n\\_channels$), drag it across the image like a moving window, and convolve the two at each position. Convolving is the sum of the elementwise multiplication product.\n",
    "$$ Conv = \\sum^i \\sum^j \\sum^k Image_{ijk} Filter_{ijk} $$\n",
    "This creates a new, smaller 2D tensor.\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz44.png\">\n",
    "(Image from \"<a href=\"http://neuralnetworksanddeeplearning.com/index.html\">Neural Networks and Deep Learning</a>\" by Michael Nielsen.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is this doing? Well, basically it's looking for features like lines and curves. If the image has a line that matches the filter, it will have a large convolution. If the image and filter don't match, the convolution will be small or zero. Take this example of finding a curve on a mouse:\n",
    "<img src=\"https://adeshpande3.github.io/assets/Filter.png\">\n",
    "<img src=\"https://adeshpande3.github.io/assets/OriginalAndFilter.png\">\n",
    "<img src=\"https://adeshpande3.github.io/assets/FirstPixelMulitiplication.png\">\n",
    "<img src=\"https://adeshpande3.github.io/assets/SecondMultiplication.png\">\n",
    "Images from <a href=\"https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/\">this blog post</a>. <a href=\"https://github.com/adeshpande3/adeshpande3.github.io/blob/master/LICENSE\">LICENSE</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution step can involve many filters. After a convolution step, the layer has to be passed through an activation function, just like with logistic regression. It's used to add nonlinearity. All these convolutions are linear functions, so stringing together several convolutions is the same as one big linear function. We need to prevent that from happening. Often, CNNs end up having several convolution + activation cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful tricks\n",
    "There are two more layers that can be added to help increase accuracy. Just trust me when I say they do that. There are pooling layers that take nonoverlapping windows in the dataset and reduce them to one number somehow. It's used to downsample. A common pooling algorithm is max pooling, that takes the maximum value in the window:\n",
    "<img src=\"https://adeshpande3.github.io/assets/MaxPool.png\">\n",
    "(Also from the blog post)  \n",
    "\n",
    "Another trick is a dropout layer, where you literally drop examples from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some vocab\n",
    "* batch: a subset of images to train at once\n",
    "* epoch: a cycle of forward and back propagation on ALL training examples\n",
    "* data augmentation: creating a larger dataset by adding transformed images, i.e. flipped and rotated image copies\n",
    "* fully connected layer: this is the start of the neural network part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install commands, assuming Python 3 only\n",
    "#!pip install tensorflow #(CPU support only)\n",
    "#!pip install tensorflow-gpu #(GPU and CPU support)\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just did this on my laptop, so I didn't install the GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras #should give you a notification that you're using the Tensorflow backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the CIFAR10 small image classification dataset included in Keras. It's got 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #this trains 32 examples at a time\n",
    "num_classes = 10\n",
    "epochs = 200 #the number of forward and back propagation cycles for ALL training examples\n",
    "data_augmentation = False #this is used if you want to augment your data with transforms of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() #the data might need to be downloaded first\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the 4th dimension is 3. That means these images have 3 color channels, namely RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential() #we're going to add all the layers one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for padding, 'valid' means don't pad, 'same' means pad with zeros\n",
    "model.add(Conv2D(32, (3, 3), padding='same', #we're going to use 32 3x3 filters with padding\n",
    "                 input_shape=x_train.shape[1:])) #the first layer needs to know the input size of the data\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3))) #another 32 3x3 filters without padding\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #max pooling with a 2x2 pool\n",
    "model.add(Dropout(0.25, )) #randomly set 25% of examples to 0, also set random seed\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same')) #now we're using 64 3x3 filters with padding\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3))) #64 3x3 filters without padding\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #max pooling with a 2x2 pool\n",
    "model.add(Dropout(0.25)) #randomly set 25% of examples to 0\n",
    "\n",
    "#add the fully connected layers (called Dense here)\n",
    "model.add(Flatten()) #we don't need images anymore, so it's easier to turn everything into vectors\n",
    "model.add(Dense(512)) #first (and only) hidden layer with 512 nodes\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) #randomly set 50% of examples to 0\n",
    "model.add(Dense(num_classes)) #output layer\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure the learning process\n",
    "model.compile(loss='categorical_crossentropy', #this is our logistic regression loss function\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#original type is uint8\n",
    "#want to normalize, so it needs to be converted to float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 336s - loss: 1.8241 - acc: 0.3289 - val_loss: 1.5697 - val_acc: 0.4353\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 316s - loss: 1.5074 - acc: 0.4530 - val_loss: 1.3398 - val_acc: 0.5195\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 324s - loss: 1.3612 - acc: 0.5119 - val_loss: 1.2333 - val_acc: 0.5632\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 313s - loss: 1.2627 - acc: 0.5496 - val_loss: 1.1397 - val_acc: 0.5956\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 312s - loss: 1.1843 - acc: 0.5799 - val_loss: 1.1207 - val_acc: 0.6038\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 311s - loss: 1.1162 - acc: 0.6043 - val_loss: 1.0152 - val_acc: 0.6439\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 312s - loss: 1.0617 - acc: 0.6250 - val_loss: 1.0159 - val_acc: 0.6452\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 312s - loss: 1.0158 - acc: 0.6446 - val_loss: 0.9233 - val_acc: 0.6780\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 315s - loss: 0.9762 - acc: 0.6582 - val_loss: 0.9616 - val_acc: 0.6622\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 312s - loss: 0.9409 - acc: 0.6698 - val_loss: 0.8775 - val_acc: 0.6965\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.9094 - acc: 0.6823 - val_loss: 0.8843 - val_acc: 0.6957\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 324s - loss: 0.8826 - acc: 0.6902 - val_loss: 0.8457 - val_acc: 0.7050\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 313s - loss: 0.8591 - acc: 0.7001 - val_loss: 0.8279 - val_acc: 0.7112\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 323s - loss: 0.8408 - acc: 0.7063 - val_loss: 0.8916 - val_acc: 0.6964\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.8211 - acc: 0.7147 - val_loss: 0.8019 - val_acc: 0.7234\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 315s - loss: 0.8043 - acc: 0.7214 - val_loss: 0.8161 - val_acc: 0.7091\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7940 - acc: 0.7255 - val_loss: 0.7625 - val_acc: 0.7376\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 314s - loss: 0.7787 - acc: 0.7320 - val_loss: 0.7436 - val_acc: 0.7499\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7707 - acc: 0.7355 - val_loss: 0.7376 - val_acc: 0.7489\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7610 - acc: 0.7382 - val_loss: 0.7603 - val_acc: 0.7449\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.7524 - acc: 0.7421 - val_loss: 0.7565 - val_acc: 0.7411\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7456 - acc: 0.7424 - val_loss: 0.7608 - val_acc: 0.7406\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7372 - acc: 0.7479 - val_loss: 0.7402 - val_acc: 0.7492\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 316s - loss: 0.7346 - acc: 0.7488 - val_loss: 0.7287 - val_acc: 0.7536\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.7298 - acc: 0.7518 - val_loss: 0.7362 - val_acc: 0.7501\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.7314 - acc: 0.7521 - val_loss: 0.7135 - val_acc: 0.7632\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 329s - loss: 0.7226 - acc: 0.7543 - val_loss: 0.7162 - val_acc: 0.7558\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.7189 - acc: 0.7565 - val_loss: 0.7282 - val_acc: 0.7569\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.7132 - acc: 0.7568 - val_loss: 0.7534 - val_acc: 0.7430\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.7049 - acc: 0.7628 - val_loss: 0.6938 - val_acc: 0.7606\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.7125 - acc: 0.7586 - val_loss: 0.7081 - val_acc: 0.7645\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.7059 - acc: 0.7628 - val_loss: 0.6982 - val_acc: 0.7611\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.7054 - acc: 0.7632 - val_loss: 0.6983 - val_acc: 0.7632\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6992 - acc: 0.7630 - val_loss: 0.7257 - val_acc: 0.7584\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6936 - acc: 0.7686 - val_loss: 0.7122 - val_acc: 0.7625\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6920 - acc: 0.7651 - val_loss: 0.6890 - val_acc: 0.7702\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 330s - loss: 0.6890 - acc: 0.7680 - val_loss: 0.6813 - val_acc: 0.7729\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6844 - acc: 0.7708 - val_loss: 0.6837 - val_acc: 0.7726\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6868 - acc: 0.7691 - val_loss: 0.6644 - val_acc: 0.7768\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6840 - acc: 0.7708 - val_loss: 0.6999 - val_acc: 0.7697\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6752 - acc: 0.7729 - val_loss: 0.6841 - val_acc: 0.7719\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.6769 - acc: 0.7747 - val_loss: 0.6840 - val_acc: 0.7714\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.6768 - acc: 0.7707 - val_loss: 0.7035 - val_acc: 0.7636\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6750 - acc: 0.7751 - val_loss: 0.6839 - val_acc: 0.7725\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6748 - acc: 0.7737 - val_loss: 0.6823 - val_acc: 0.7713\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 322s - loss: 0.6674 - acc: 0.7772 - val_loss: 0.7315 - val_acc: 0.7702\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6738 - acc: 0.7749 - val_loss: 0.7071 - val_acc: 0.7694\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6689 - acc: 0.7752 - val_loss: 0.6967 - val_acc: 0.7672\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 333s - loss: 0.6704 - acc: 0.7763 - val_loss: 0.6736 - val_acc: 0.7820\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 323s - loss: 0.6629 - acc: 0.7784 - val_loss: 0.7119 - val_acc: 0.7693\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6707 - acc: 0.7776 - val_loss: 0.7017 - val_acc: 0.7685\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.6627 - acc: 0.7794 - val_loss: 0.7224 - val_acc: 0.7677\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6676 - acc: 0.7776 - val_loss: 0.6728 - val_acc: 0.7761\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6663 - acc: 0.7789 - val_loss: 0.7153 - val_acc: 0.7645\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 321s - loss: 0.6615 - acc: 0.7818 - val_loss: 0.7420 - val_acc: 0.7614\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6655 - acc: 0.7789 - val_loss: 0.6973 - val_acc: 0.7628\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6647 - acc: 0.7800 - val_loss: 0.6876 - val_acc: 0.7711\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6575 - acc: 0.7797 - val_loss: 0.6933 - val_acc: 0.7735\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6641 - acc: 0.7782 - val_loss: 0.7126 - val_acc: 0.7812\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 332s - loss: 0.6624 - acc: 0.7822 - val_loss: 0.6729 - val_acc: 0.7818\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6581 - acc: 0.7803 - val_loss: 0.7183 - val_acc: 0.7633\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.6539 - acc: 0.7821 - val_loss: 0.7685 - val_acc: 0.7570\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.6637 - acc: 0.7800 - val_loss: 0.7280 - val_acc: 0.7550\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6571 - acc: 0.7827 - val_loss: 0.7135 - val_acc: 0.7657\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6618 - acc: 0.7804 - val_loss: 0.6888 - val_acc: 0.7827\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6539 - acc: 0.7819 - val_loss: 0.7367 - val_acc: 0.7730\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6583 - acc: 0.7822 - val_loss: 0.6868 - val_acc: 0.7748\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6523 - acc: 0.7837 - val_loss: 0.6797 - val_acc: 0.7791\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 317s - loss: 0.6571 - acc: 0.7813 - val_loss: 0.6945 - val_acc: 0.7695\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6572 - acc: 0.7840 - val_loss: 0.7022 - val_acc: 0.7709\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6484 - acc: 0.7852 - val_loss: 0.6921 - val_acc: 0.7794\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 329s - loss: 0.6588 - acc: 0.7825 - val_loss: 0.6991 - val_acc: 0.7781\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6586 - acc: 0.7834 - val_loss: 0.7934 - val_acc: 0.7367\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 318s - loss: 0.6572 - acc: 0.7807 - val_loss: 0.6627 - val_acc: 0.7799\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6535 - acc: 0.7857 - val_loss: 0.7131 - val_acc: 0.7666\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6525 - acc: 0.7835 - val_loss: 0.7085 - val_acc: 0.7733\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 320s - loss: 0.6531 - acc: 0.7851 - val_loss: 0.7215 - val_acc: 0.7755\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6564 - acc: 0.7838 - val_loss: 0.7317 - val_acc: 0.7620\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6601 - acc: 0.7836 - val_loss: 0.7224 - val_acc: 0.7622\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6582 - acc: 0.7820 - val_loss: 0.6790 - val_acc: 0.7769\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6617 - acc: 0.7822 - val_loss: 0.6798 - val_acc: 0.7783\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6562 - acc: 0.7816 - val_loss: 0.7571 - val_acc: 0.7521\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6632 - acc: 0.7820 - val_loss: 0.6932 - val_acc: 0.7775\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6574 - acc: 0.7841 - val_loss: 0.7022 - val_acc: 0.7708\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 319s - loss: 0.6574 - acc: 0.7819 - val_loss: 0.6787 - val_acc: 0.7812\n",
      "Epoch 86/200\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6607 - acc: 0.7840"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a6a8d46b8afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               shuffle=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1163\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                                                    verbose=0)\n\u001b[0m\u001b[1;32m   1165\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This will take a while on a CPU, but it's still doable\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
